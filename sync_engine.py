#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MDæ–‡æ¡£åŒæ­¥å¼•æ“
æ ¸å¿ƒåŒæ­¥é€»è¾‘ï¼Œç®¡ç†è§„åˆ™å’Œæ‰§è¡ŒåŒæ­¥
"""

import json
import logging
import logging.handlers
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime

from apple_bridge import AppleScriptBridge
from rules import (
    SyncRule, 
    UpdateExistingRule,
    CreateNewRule,
    FileTypeRule,
    FolderMappingRule,
    TitlePrefixRule,
    ClaudeAutoSyncRule
)

class MDSyncEngine:
    """MDæ–‡æ¡£åŒæ­¥å¼•æ“"""
    
    def __init__(self, config_path: str = None):
        """
        åˆå§‹åŒ–åŒæ­¥å¼•æ“
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_path = config_path or "config.json"
        self.config = self.load_config()
        
        # è®¾ç½®æ—¥å¿—
        self.setup_logging()
        self.logger = logging.getLogger(__name__)
        
        # åˆå§‹åŒ–AppleScriptæ¡¥æ¥
        notes_config = self.config.get('notes_config', {})
        self.apple_bridge = AppleScriptBridge(
            account=notes_config.get('account', 'iCloud'),
            default_folder=notes_config.get('default_folder', 'Notes')
        )
        
        # åˆå§‹åŒ–è§„åˆ™åˆ—è¡¨
        self.rules: List[SyncRule] = []
        self.setup_default_rules()
        
        self.logger.info("MDåŒæ­¥å¼•æ“åˆå§‹åŒ–å®Œæˆ")
    
    def load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            if Path(self.config_path).exists():
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    print(f"âœ… å·²åŠ è½½é…ç½®æ–‡ä»¶: {self.config_path}")
                    return config
            else:
                print(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_path}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                return self.get_default_config()
        except Exception as e:
            print(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return self.get_default_config()
    
    def get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "sync_rules": {
                "auto_update": True,
                "backup_before_update": False,
                "max_file_size_mb": 50,
                "encoding": "utf-8",
                "excluded_patterns": ["*.tmp.md", "*draft*", ".*", "_*"],
                "folder_mappings": {
                    "work": "å·¥ä½œç¬”è®°",
                    "personal": "ä¸ªäººç¬”è®°", 
                    "tech": "æŠ€æœ¯æ–‡æ¡£",
                    "claude": "Claudeæ–‡æ¡£",
                    "default": "Notes"
                }
            },
            "notes_config": {
                "account": "iCloud",
                "default_folder": "Notes",
                "title_prefix": "",
                "title_suffix": "",
                "add_timestamp": False,
                "add_source_path": True
            },
            "logging": {
                "level": "INFO",
                "log_file": "logs/sync.log",
                "max_log_size_mb": 10,
                "backup_count": 5,
                "console_output": True
            }
        }
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        log_config = self.config.get('logging', {})
        
        # åˆ›å»ºlogsç›®å½•
        log_file = Path(log_config.get('log_file', 'logs/sync.log'))
        log_file.parent.mkdir(exist_ok=True)
        
        # é…ç½®root logger
        root_logger = logging.getLogger()
        root_logger.setLevel(getattr(logging, log_config.get('level', 'INFO')))
        
        # æ¸…é™¤å·²æœ‰çš„å¤„ç†å™¨
        root_logger.handlers.clear()
        
        # æ–‡ä»¶å¤„ç†å™¨ï¼ˆå¸¦è½®è½¬ï¼‰
        max_size = log_config.get('max_log_size_mb', 10) * 1024 * 1024
        backup_count = log_config.get('backup_count', 5)
        
        file_handler = logging.handlers.RotatingFileHandler(
            log_file,
            maxBytes=max_size,
            backupCount=backup_count,
            encoding='utf-8'
        )
        file_formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        file_handler.setFormatter(file_formatter)
        root_logger.addHandler(file_handler)
        
        # æ§åˆ¶å°å¤„ç†å™¨
        if log_config.get('console_output', True):
            console_handler = logging.StreamHandler()
            console_formatter = logging.Formatter(
                '%(levelname)s - %(message)s'
            )
            console_handler.setFormatter(console_formatter)
            root_logger.addHandler(console_handler)
    
    def setup_default_rules(self):
        """è®¾ç½®é»˜è®¤åŒæ­¥è§„åˆ™"""
        # åŸºç¡€è§„åˆ™ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
        default_rules = [
            FileTypeRule(priority=95),                    # æ–‡ä»¶ç±»å‹è¿‡æ»¤
            ClaudeAutoSyncRule(priority=100)              # Claudeå®Œæ•´åŒæ­¥æµç¨‹
        ]
        
        for rule in default_rules:
            self.add_rule(rule)
        
        self.logger.info(f"å·²è®¾ç½® {len(default_rules)} ä¸ªé»˜è®¤è§„åˆ™ï¼ˆåŒ…å«Claudeä¸“ç”¨è§„åˆ™ï¼‰")
    
    def add_rule(self, rule: SyncRule):
        """
        æ·»åŠ åŒæ­¥è§„åˆ™
        
        Args:
            rule: åŒæ­¥è§„åˆ™å®ä¾‹
        """
        self.rules.append(rule)
        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆä¼˜å…ˆçº§é«˜çš„å…ˆæ‰§è¡Œï¼‰
        self.rules.sort(key=lambda r: r.priority, reverse=True)
        self.logger.debug(f"æ·»åŠ è§„åˆ™: {rule}")
    
    def remove_rule(self, rule_name: str) -> bool:
        """
        ç§»é™¤æŒ‡å®šåç§°çš„è§„åˆ™
        
        Args:
            rule_name: è§„åˆ™åç§°
            
        Returns:
            ç§»é™¤æˆåŠŸè¿”å›True
        """
        original_count = len(self.rules)
        self.rules = [r for r in self.rules if r.name != rule_name]
        
        success = len(self.rules) < original_count
        if success:
            self.logger.info(f"å·²ç§»é™¤è§„åˆ™: {rule_name}")
        else:
            self.logger.warning(f"è§„åˆ™ä¸å­˜åœ¨: {rule_name}")
        
        return success
    
    def list_rules(self) -> List[SyncRule]:
        """è·å–æ‰€æœ‰è§„åˆ™åˆ—è¡¨"""
        return self.rules.copy()
    
    def enable_rule(self, rule_name: str) -> bool:
        """å¯ç”¨è§„åˆ™"""
        for rule in self.rules:
            if rule.name == rule_name:
                rule.enabled = True
                self.logger.info(f"å·²å¯ç”¨è§„åˆ™: {rule_name}")
                return True
        
        self.logger.warning(f"è§„åˆ™ä¸å­˜åœ¨: {rule_name}")
        return False
    
    def disable_rule(self, rule_name: str) -> bool:
        """ç¦ç”¨è§„åˆ™"""
        for rule in self.rules:
            if rule.name == rule_name:
                rule.enabled = False
                self.logger.info(f"å·²ç¦ç”¨è§„åˆ™: {rule_name}")
                return True
        
        self.logger.warning(f"è§„åˆ™ä¸å­˜åœ¨: {rule_name}")
        return False
    
    def sync_file(self, md_file_path: str, dry_run: bool = False) -> bool:
        """
        åŒæ­¥å•ä¸ªæ–‡ä»¶
        
        Args:
            md_file_path: MDæ–‡ä»¶è·¯å¾„
            dry_run: æ˜¯å¦åªæ˜¯è¯•è¿è¡Œï¼ˆä¸å®é™…æ‰§è¡Œï¼‰
            
        Returns:
            åŒæ­¥æˆåŠŸè¿”å›True
        """
        md_file = Path(md_file_path)
        
        if not md_file.exists():
            self.logger.error(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {md_file}")
            return False
        
        if not md_file.is_file():
            self.logger.error(f"âŒ ä¸æ˜¯æ–‡ä»¶: {md_file}")
            return False
        
        self.logger.info(f"å¼€å§‹åŒæ­¥æ–‡ä»¶: {md_file.name}")
        
        # è®¾ç½®è¯•è¿è¡Œé…ç½®
        config = self.config.copy()
        if dry_run:
            config['dry_run'] = True
            self.logger.info("ğŸ”¸ è¯•è¿è¡Œæ¨¡å¼")
        
        # åº”ç”¨æ‰€æœ‰è§„åˆ™
        success_count = 0
        applied_rules = []
        
        for rule in self.rules:
            if not rule.enabled:
                continue
            
            try:
                # æ£€æŸ¥è§„åˆ™æ˜¯å¦åº”è¯¥åº”ç”¨
                if rule.should_apply(md_file, config):
                    applied_rules.append(rule.name)
                    
                    # æ‰§è¡Œè§„åˆ™
                    if not dry_run:
                        success = rule.execute(md_file, self.apple_bridge, config)
                        if success:
                            success_count += 1
                        else:
                            self.logger.error(f"âŒ è§„åˆ™æ‰§è¡Œå¤±è´¥: {rule.name}")
                    else:
                        # è¯•è¿è¡Œæ¨¡å¼
                        rule.execute(md_file, self.apple_bridge, config)
                        success_count += 1
                
            except Exception as e:
                self.logger.error(f"âŒ è§„åˆ™æ‰§è¡Œå¼‚å¸¸: {rule.name} - {e}")
        
        if applied_rules:
            self.logger.info(f"åº”ç”¨äº† {len(applied_rules)} ä¸ªè§„åˆ™: {', '.join(applied_rules)}")
            
            if not dry_run:
                if success_count > 0:
                    self.logger.info(f"âœ… åŒæ­¥å®Œæˆ: {md_file.name}")
                    return True
                else:
                    self.logger.error(f"âŒ æ‰€æœ‰è§„åˆ™æ‰§è¡Œå¤±è´¥: {md_file.name}")
                    return False
            else:
                self.logger.info(f"ğŸ”¸ è¯•è¿è¡Œå®Œæˆ: {md_file.name}")
                return True
        else:
            self.logger.info(f"â­ï¸ æ²¡æœ‰é€‚ç”¨çš„è§„åˆ™: {md_file.name}")
            return True
    
    def sync_folder(self, folder_path: str, recursive: bool = True, dry_run: bool = False) -> Dict[str, Any]:
        """
        æ‰¹é‡åŒæ­¥æ–‡ä»¶å¤¹
        
        Args:
            folder_path: æ–‡ä»¶å¤¹è·¯å¾„
            recursive: æ˜¯å¦é€’å½’å¤„ç†å­ç›®å½•
            dry_run: æ˜¯å¦åªæ˜¯è¯•è¿è¡Œ
            
        Returns:
            åŒæ­¥ç»Ÿè®¡ä¿¡æ¯
        """
        folder = Path(folder_path)
        
        if not folder.exists():
            self.logger.error(f"âŒ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder}")
            return {'error': 'æ–‡ä»¶å¤¹ä¸å­˜åœ¨'}
        
        if not folder.is_dir():
            self.logger.error(f"âŒ ä¸æ˜¯æ–‡ä»¶å¤¹: {folder}")
            return {'error': 'ä¸æ˜¯æ–‡ä»¶å¤¹'}
        
        self.logger.info(f"å¼€å§‹æ‰¹é‡åŒæ­¥: {folder}")
        
        # æŸ¥æ‰¾MDæ–‡ä»¶
        if recursive:
            md_files = list(folder.rglob("*.md"))
        else:
            md_files = list(folder.glob("*.md"))
        
        self.logger.info(f"æ‰¾åˆ° {len(md_files)} ä¸ªMDæ–‡ä»¶")
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'total_files': len(md_files),
            'success_count': 0,
            'failure_count': 0,
            'skipped_count': 0,
            'start_time': datetime.now(),
            'processed_files': []
        }
        
        # å¤„ç†æ¯ä¸ªæ–‡ä»¶
        for md_file in md_files:
            try:
                success = self.sync_file(str(md_file), dry_run)
                
                file_info = {
                    'path': str(md_file),
                    'name': md_file.name,
                    'success': success,
                    'timestamp': datetime.now()
                }
                
                if success:
                    stats['success_count'] += 1
                else:
                    stats['failure_count'] += 1
                
                stats['processed_files'].append(file_info)
                
            except Exception as e:
                self.logger.error(f"âŒ å¤„ç†æ–‡ä»¶å¼‚å¸¸: {md_file} - {e}")
                stats['failure_count'] += 1
                
                stats['processed_files'].append({
                    'path': str(md_file),
                    'name': md_file.name,
                    'success': False,
                    'error': str(e),
                    'timestamp': datetime.now()
                })
        
        # å®Œæˆç»Ÿè®¡
        stats['end_time'] = datetime.now()
        stats['duration'] = (stats['end_time'] - stats['start_time']).total_seconds()
        
        # è¾“å‡ºç»Ÿè®¡ç»“æœ
        self.logger.info(f"ğŸ“Š æ‰¹é‡åŒæ­¥å®Œæˆ:")
        self.logger.info(f"   æ€»æ–‡ä»¶æ•°: {stats['total_files']}")
        self.logger.info(f"   æˆåŠŸ: {stats['success_count']}")
        self.logger.info(f"   å¤±è´¥: {stats['failure_count']}")
        self.logger.info(f"   è€—æ—¶: {stats['duration']:.2f}ç§’")
        
        return stats
    
    def sync_files(self, file_paths: List[str], dry_run: bool = False) -> Dict[str, Any]:
        """
        æ‰¹é‡åŒæ­¥æŒ‡å®šæ–‡ä»¶åˆ—è¡¨
        
        Args:
            file_paths: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            dry_run: æ˜¯å¦åªæ˜¯è¯•è¿è¡Œ
            
        Returns:
            åŒæ­¥ç»Ÿè®¡ä¿¡æ¯
        """
        self.logger.info(f"å¼€å§‹æ‰¹é‡åŒæ­¥ {len(file_paths)} ä¸ªæ–‡ä»¶")
        
        stats = {
            'total_files': len(file_paths),
            'success_count': 0,
            'failure_count': 0,
            'start_time': datetime.now(),
            'processed_files': []
        }
        
        for file_path in file_paths:
            try:
                success = self.sync_file(file_path, dry_run)
                
                file_info = {
                    'path': file_path,
                    'name': Path(file_path).name,
                    'success': success,
                    'timestamp': datetime.now()
                }
                
                if success:
                    stats['success_count'] += 1
                else:
                    stats['failure_count'] += 1
                
                stats['processed_files'].append(file_info)
                
            except Exception as e:
                self.logger.error(f"âŒ å¤„ç†æ–‡ä»¶å¼‚å¸¸: {file_path} - {e}")
                stats['failure_count'] += 1
                
                stats['processed_files'].append({
                    'path': file_path,
                    'name': Path(file_path).name,
                    'success': False,
                    'error': str(e),
                    'timestamp': datetime.now()
                })
        
        stats['end_time'] = datetime.now()
        stats['duration'] = (stats['end_time'] - stats['start_time']).total_seconds()
        
        self.logger.info(f"ğŸ“Š æ‰¹é‡åŒæ­¥å®Œæˆ: æˆåŠŸ {stats['success_count']}/{stats['total_files']}")
        
        return stats
    
    def get_notes_info(self) -> Dict[str, Any]:
        """è·å–å¤‡å¿˜å½•åº”ç”¨ä¿¡æ¯"""
        try:
            folders = self.apple_bridge.get_folders()
            total_notes = 0
            
            folder_info = {}
            for folder in folders:
                notes = self.apple_bridge.get_existing_notes(folder)
                folder_info[folder] = len(notes)
                total_notes += len(notes)
            
            return {
                'total_folders': len(folders),
                'total_notes': total_notes,
                'folders': folder_info,
                'account': self.apple_bridge.account
            }
            
        except Exception as e:
            self.logger.error(f"è·å–å¤‡å¿˜å½•ä¿¡æ¯å¤±è´¥: {e}")
            return {'error': str(e)}
    
    def validate_config(self) -> List[str]:
        """éªŒè¯é…ç½®æ–‡ä»¶"""
        issues = []
        
        # æ£€æŸ¥å¿…éœ€çš„é…ç½®é¡¹
        required_configs = [
            ('sync_rules', dict),
            ('notes_config', dict),
            ('logging', dict)
        ]
        
        for key, expected_type in required_configs:
            if key not in self.config:
                issues.append(f"ç¼ºå°‘é…ç½®é¡¹: {key}")
            elif not isinstance(self.config[key], expected_type):
                issues.append(f"é…ç½®é¡¹ç±»å‹é”™è¯¯: {key} åº”è¯¥æ˜¯ {expected_type.__name__}")
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°é™åˆ¶
        max_size = self.config.get('sync_rules', {}).get('max_file_size_mb')
        if max_size is not None and (not isinstance(max_size, (int, float)) or max_size <= 0):
            issues.append("max_file_size_mb åº”è¯¥æ˜¯æ­£æ•°")
        
        # æ£€æŸ¥æ—¥å¿—é…ç½®
        log_level = self.config.get('logging', {}).get('level', 'INFO')
        valid_levels = ['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL']
        if log_level not in valid_levels:
            issues.append(f"æ— æ•ˆçš„æ—¥å¿—çº§åˆ«: {log_level}ï¼Œåº”è¯¥æ˜¯ {valid_levels} ä¹‹ä¸€")
        
        return issues